{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCSS 588 Ensemble Project Winter  2019\n",
    "\n",
    "#### This notebook contains the code to calculate the accuracy of a decision tree and extra tree classifier trained, and then using the coefficients of the trained classifier to deterine the important genes. \n",
    "#### To summarize, here are the steps this  notebook takes:\n",
    "####  Step 1. Load the gene data for 1000 genes.\n",
    "#### Step 2. Remove the entry_id column from this data\n",
    "#### Step 3. Train a Decision Tree Classifier using this data using 5 fold cross validation\n",
    "#### Step 5: Train an Extra Trees Classifier using this data using 5 fold cross validation\n",
    "#### Step 4: Determine the genes that are important using the Extra Trees Classifier\n",
    "#### Step 6: Determine the genes that are important using the Decision Classifier\n",
    "\n",
    "### Dependencies\n",
    "### Data Files\n",
    "\n",
    "#### 1. The file  data\\\\aml.data.RNA.1k.csv - this has the  data\n",
    "#### 2. The file data\\\\aml.data.labels.csv  - this file  has the Y values - the class we would like to predict\n",
    "\n",
    "### Packages\n",
    "\n",
    "#### This code depends on the following python packages:\n",
    "#####  os, sklearn, pandas, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We load the training data and the testing data. \n",
    "####  a. First laod the RNA genes data file. \n",
    "####  Also drop the entry_id column from it since that is a primary key and not required for  training or classification purposes. The data from both the files match based on the entry_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\radeshpa\\\\Desktop\\\\New folder (2)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. First for 1k data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSize = \"1k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 1017)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure these paths are valid\n",
    "import pandas as pd\n",
    "inputDataFile = \"data\\\\aml.data.RNA.1k.csv\"\n",
    "labelDataFile = \"data\\\\aml.data.labels.csv\"\n",
    "X = pd.read_csv(os.path.join(os.getcwd(), inputDataFile))\n",
    "# Drop the entry id column\n",
    "X = X.drop(X.columns[0], axis=1)\n",
    "X.head()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Load the output classifier data. Once again, drop the risk_entry columnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv(os.path.join(os.getcwd(), labelDataFile))\n",
    "# Drop the entry id\n",
    "y = y.drop(y.columns[0], axis=1)\n",
    "y.head()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Generate Training and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.  Create an instance of KFold to split the data into 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "splitCount = 5\n",
    "\n",
    "# Setting the random state ensures identical results.\n",
    "\n",
    "kFolds = KFold(n_splits = splitCount, shuffle=False, random_state=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Now perform 5-fold cross validation for  decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  import sys\n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  import sys\n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  import sys\n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  import sys\n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[86.11111111111111,\n",
       " 75.0,\n",
       " 85.71428571428571,\n",
       " 88.57142857142857,\n",
       " 82.85714285714286]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allTreeAccuracyValues = []\n",
    "allTreeFeatureImportanceValues = []\n",
    "allTreeModels = []\n",
    "\n",
    "for train_index, test_index in kFolds.split(X):\n",
    "    X_train, X_test = X.ix[train_index], X.ix[test_index]\n",
    "    y_train, y_test = y.ix[train_index], y.ix[test_index]\n",
    "    tree = DecisionTreeClassifier()\n",
    "    treeResult = tree.fit(X_train, y_train)\n",
    "    y_prediction = treeResult.predict(X_test)\n",
    "    y_actual = y_test['risk'].values\n",
    "    accuracy = (y_prediction == y_actual).sum()/len(y_actual)\n",
    "    allTreeAccuracyValues.append(accuracy * 100)\n",
    "    allTreeFeatureImportanceValues.append(treeResult.feature_importances_)\n",
    "    allTreeModels.append(treeResult)\n",
    "\n",
    "allTreeAccuracyValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write the accuracies of the decision tree to  a csv file for analyzing later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy\n",
       "0  86.111111\n",
       "1  75.000000\n",
       "2  85.714286\n",
       "3  88.571429\n",
       "4  82.857143"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeAccuracyValuesFrame = pd.DataFrame(allTreeAccuracyValues, columns=['Accuracy'])\n",
    "treeAccuracyValuesFrame.to_csv(\"data\\\\{}_tree_accuracyValues.csv\".format(dataSize))\n",
    "treeAccuracyValuesFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Perform 5-fold cross validation using the ExtraTreesClassifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\users\\radeshpa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[86.11111111111111,\n",
       " 94.44444444444444,\n",
       " 94.28571428571428,\n",
       " 88.57142857142857,\n",
       " 88.57142857142857]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "allExtraTreeAccuracyValues = []\n",
    "allExtraTreeFeatureImportanceValues = []\n",
    "allExtraTreeModels = []\n",
    "\n",
    "\n",
    "for train_index, test_index in kFolds.split(X):\n",
    "    X_train, X_test = X.ix[train_index], X.ix[test_index]\n",
    "    y_train, y_test = y.ix[train_index], y.ix[test_index]\n",
    "    num_trees = 10\n",
    "    extraTree = ExtraTreesClassifier(n_estimators=num_trees)\n",
    "    extraTreeResult = extraTree.fit(X_train, y_train)\n",
    "    y_prediction = extraTreeResult.predict(X_test)\n",
    "    y_actual = y_test['risk'].values\n",
    "    accuracy = (y_prediction == y_actual).sum()/len(y_actual)\n",
    "    \n",
    "    allExtraTreeAccuracyValues.append(accuracy * 100)\n",
    "    allExtraTreeFeatureImportanceValues.append(extraTreeResult.feature_importances_)\n",
    "    allExtraTreeModels.append(treeResult)\n",
    "    \n",
    "allExtraTreeAccuracyValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write the accuracies of the Extra Trees Classifier to a csv file so we can analyze them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy\n",
       "0  86.111111\n",
       "1  94.444444\n",
       "2  94.285714\n",
       "3  88.571429\n",
       "4  88.571429"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraTreeAccuracyValuesFrame = pd.DataFrame(allExtraTreeAccuracyValues, columns=['Accuracy'])\n",
    "extraTreeAccuracyValuesFrame.to_csv(\"data\\\\{}_extratrees_accuracyValues.csv\".format(dataSize))\n",
    "extraTreeAccuracyValuesFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3.  Calculate the  Feature Importance Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Calculate for Extra Trees Classifier Feature Importance Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. First acquire all the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnNames = X.columns.get_values().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Get the important features for the extra trees classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000000003.13</th>\n",
       "      <th>ENSG00000002586.16</th>\n",
       "      <th>ENSG00000003436.13</th>\n",
       "      <th>ENSG00000004139.12</th>\n",
       "      <th>ENSG00000004399.11</th>\n",
       "      <th>ENSG00000005073.5</th>\n",
       "      <th>ENSG00000005108.14</th>\n",
       "      <th>ENSG00000005156.10</th>\n",
       "      <th>ENSG00000005249.11</th>\n",
       "      <th>ENSG00000005381.7</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000278969.1</th>\n",
       "      <th>ENSG00000279692.1</th>\n",
       "      <th>ENSG00000279766.1</th>\n",
       "      <th>ENSG00000279978.1</th>\n",
       "      <th>ENSG00000280206.1</th>\n",
       "      <th>ENSG00000280255.1</th>\n",
       "      <th>ENSG00000280303.2</th>\n",
       "      <th>ENSG00000280721.1</th>\n",
       "      <th>ENSG00000280777.1</th>\n",
       "      <th>ENSG00000281205.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.020155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.016872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.009039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1017 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENSG00000000003.13  ENSG00000002586.16  ENSG00000003436.13  \\\n",
       "0            0.000000                 0.0                 0.0   \n",
       "1            0.012526                 0.0                 0.0   \n",
       "2            0.000000                 0.0                 0.0   \n",
       "3            0.000000                 0.0                 0.0   \n",
       "4            0.000000                 0.0                 0.0   \n",
       "\n",
       "   ENSG00000004139.12  ENSG00000004399.11  ENSG00000005073.5  \\\n",
       "0            0.001435            0.020155           0.000000   \n",
       "1            0.000000            0.000000           0.004464   \n",
       "2            0.000000            0.000000           0.000000   \n",
       "3            0.000000            0.000000           0.000000   \n",
       "4            0.000000            0.000000           0.001924   \n",
       "\n",
       "   ENSG00000005108.14  ENSG00000005156.10  ENSG00000005249.11  \\\n",
       "0            0.000000            0.000000                 0.0   \n",
       "1            0.000000            0.000000                 0.0   \n",
       "2            0.000000            0.003538                 0.0   \n",
       "3            0.000000            0.000000                 0.0   \n",
       "4            0.008203            0.000000                 0.0   \n",
       "\n",
       "   ENSG00000005381.7  ...  ENSG00000278969.1  ENSG00000279692.1  \\\n",
       "0                0.0  ...                0.0                0.0   \n",
       "1                0.0  ...                0.0                0.0   \n",
       "2                0.0  ...                0.0                0.0   \n",
       "3                0.0  ...                0.0                0.0   \n",
       "4                0.0  ...                0.0                0.0   \n",
       "\n",
       "   ENSG00000279766.1  ENSG00000279978.1  ENSG00000280206.1  ENSG00000280255.1  \\\n",
       "0           0.000000           0.000000           0.002391                0.0   \n",
       "1           0.002066           0.016872           0.000000                0.0   \n",
       "2           0.000000           0.000000           0.002949                0.0   \n",
       "3           0.000604           0.000000           0.000000                0.0   \n",
       "4           0.000663           0.000000           0.000000                0.0   \n",
       "\n",
       "   ENSG00000280303.2  ENSG00000280721.1  ENSG00000280777.1  ENSG00000281205.1  \n",
       "0           0.000510            0.00000           0.000000           0.000000  \n",
       "1           0.000000            0.00000           0.000000           0.002353  \n",
       "2           0.000000            0.00041           0.002764           0.009039  \n",
       "3           0.000000            0.00000           0.000000           0.000000  \n",
       "4           0.002624            0.00000           0.000000           0.001443  \n",
       "\n",
       "[5 rows x 1017 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "extraTreeGiniValuesFrame = pd.DataFrame(columns=columnNames)\n",
    "extraTreeGiniValuesFrame.columns = columnNames\n",
    "\n",
    "# Iterate over the feature importance values for every model.\n",
    "for i in range(len(allExtraTreeFeatureImportanceValues)):    \n",
    "    extraTreeGiniValuesFrame = extraTreeGiniValuesFrame.append(dict(zip(columnNames, allExtraTreeFeatureImportanceValues[i])), ignore_index=True)\n",
    "\n",
    "directory = 'data\\\\{}'.format(dataSize)\n",
    "import os\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Write the results to a CSV File.\n",
    "outputFileName = 'data\\\\{}\\\\{}_extra_tree_feature_importance_all.csv'.format(dataSize, dataSize)\n",
    "extraTreeGiniValuesFrame.to_csv(outputFileName)\n",
    "extraTreeGiniValuesFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Now get the mean for every gene, and then sort the genes based on mean importance. This is useful for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000198842.8</th>\n",
       "      <th>ENSG00000122592.7</th>\n",
       "      <th>ENSG00000139117.12</th>\n",
       "      <th>ENSG00000078399.14</th>\n",
       "      <th>ENSG00000257718.1</th>\n",
       "      <th>ENSG00000105997.21</th>\n",
       "      <th>ENSG00000105996.6</th>\n",
       "      <th>ENSG00000132975.7</th>\n",
       "      <th>ENSG00000091490.9</th>\n",
       "      <th>ENSG00000228401.4</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000075218.17</th>\n",
       "      <th>ENSG00000157510.12</th>\n",
       "      <th>ENSG00000159842.13</th>\n",
       "      <th>ENSG00000158457.5</th>\n",
       "      <th>ENSG00000002586.16</th>\n",
       "      <th>ENSG00000158747.12</th>\n",
       "      <th>ENSG00000159055.3</th>\n",
       "      <th>ENSG00000159399.8</th>\n",
       "      <th>ENSG00000159714.9</th>\n",
       "      <th>ENSG00000158560.13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021913</td>\n",
       "      <td>0.020001</td>\n",
       "      <td>0.018951</td>\n",
       "      <td>0.016269</td>\n",
       "      <td>0.015497</td>\n",
       "      <td>0.014296</td>\n",
       "      <td>0.013336</td>\n",
       "      <td>0.012942</td>\n",
       "      <td>0.01065</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1017 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENSG00000198842.8  ENSG00000122592.7  ENSG00000139117.12  \\\n",
       "0           0.021913           0.020001            0.018951   \n",
       "\n",
       "   ENSG00000078399.14  ENSG00000257718.1  ENSG00000105997.21  \\\n",
       "0            0.016269           0.015497            0.014296   \n",
       "\n",
       "   ENSG00000105996.6  ENSG00000132975.7  ENSG00000091490.9  ENSG00000228401.4  \\\n",
       "0           0.013336           0.012942            0.01065           0.010621   \n",
       "\n",
       "   ...  ENSG00000075218.17  ENSG00000157510.12  ENSG00000159842.13  \\\n",
       "0  ...                 0.0                 0.0                 0.0   \n",
       "\n",
       "   ENSG00000158457.5  ENSG00000002586.16  ENSG00000158747.12  \\\n",
       "0                0.0                 0.0                 0.0   \n",
       "\n",
       "   ENSG00000159055.3  ENSG00000159399.8  ENSG00000159714.9  ENSG00000158560.13  \n",
       "0                0.0                0.0                0.0                 0.0  \n",
       "\n",
       "[1 rows x 1017 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean importance for all the genes for Extra Trees\n",
    "extraTreeGiniValuesFrameMean = pd.DataFrame(columns = extraTreeGiniValuesFrame.columns)\n",
    "extraTreeGiniValuesFrameMean.loc[0] = extraTreeGiniValuesFrame.mean()\n",
    "# Sort the results based on importance values\n",
    "extraTreeGiniValuesFrameMean = extraTreeGiniValuesFrameMean.sort_values(extraTreeGiniValuesFrameMean.last_valid_index(), axis=1, ascending = False)\n",
    "extraTreeGiniValuesFrameMean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Write the importance to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the results to a CSV File\n",
    "extraTreeGiniValuesFrameMean.transpose().to_csv(\"data\\\\{}\\\\{}_extra_trees_feature_importance_average.csv\".format(dataSize, dataSize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Importance for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., ..., 0., 0., 0.]),\n",
       " array([0., 0., 0., ..., 0., 0., 0.]),\n",
       " array([0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.05606721]),\n",
       " array([0., 0., 0., ..., 0., 0., 0.]),\n",
       " array([0., 0., 0., ..., 0., 0., 0.])]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allTreeFeatureImportanceValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a frame that has the coefficients for every fold. Write that frame to a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "decisionTreeGiniValuesFrame = pd.DataFrame(columns=columnNames)\n",
    "decisionTreeGiniValuesFrame.columns = columnNames\n",
    "decisionTreeGiniValuesFrame\n",
    "\n",
    "for i in range(len(allTreeFeatureImportanceValues)):    \n",
    "    decisionTreeGiniValuesFrame = decisionTreeGiniValuesFrame.append(dict(zip(columnNames, allTreeFeatureImportanceValues[i])), ignore_index=True)\n",
    "\n",
    "decisionTreeGiniValuesFrame\n",
    "outputFileName = 'data\\\\{}\\\\{}_decisiontree_feature_importance_all.csv'.format(dataSize, dataSize)\n",
    "decisionTreeGiniValuesFrame.to_csv(outputFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTreeGiniValuesFrame\n",
    "outputFileName = 'data\\\\{}\\\\{}_decisiontree_feature_importance_all.csv'.format(dataSize, dataSize)\n",
    "decisionTreeGiniValuesFrame.to_csv(outputFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For analysis, acquire the mean value of the importance of every gene for all the folds. Write that to a csv file as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000170893.3</th>\n",
       "      <th>ENSG00000105997.21</th>\n",
       "      <th>ENSG00000267453.5</th>\n",
       "      <th>ENSG00000254369.5</th>\n",
       "      <th>ENSG00000105996.6</th>\n",
       "      <th>ENSG00000197253.12</th>\n",
       "      <th>ENSG00000135842.15</th>\n",
       "      <th>ENSG00000270182.1</th>\n",
       "      <th>ENSG00000264918.1</th>\n",
       "      <th>ENSG00000171467.14</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000133985.2</th>\n",
       "      <th>ENSG00000134072.9</th>\n",
       "      <th>ENSG00000134242.14</th>\n",
       "      <th>ENSG00000134470.18</th>\n",
       "      <th>ENSG00000134531.8</th>\n",
       "      <th>ENSG00000134569.8</th>\n",
       "      <th>ENSG00000134590.12</th>\n",
       "      <th>ENSG00000134716.8</th>\n",
       "      <th>ENSG00000135069.12</th>\n",
       "      <th>ENSG00000158560.13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.511277</td>\n",
       "      <td>0.119326</td>\n",
       "      <td>0.053003</td>\n",
       "      <td>0.038966</td>\n",
       "      <td>0.034773</td>\n",
       "      <td>0.032448</td>\n",
       "      <td>0.025288</td>\n",
       "      <td>0.019858</td>\n",
       "      <td>0.015346</td>\n",
       "      <td>0.011879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1017 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENSG00000170893.3  ENSG00000105997.21  ENSG00000267453.5  \\\n",
       "0           0.511277            0.119326           0.053003   \n",
       "\n",
       "   ENSG00000254369.5  ENSG00000105996.6  ENSG00000197253.12  \\\n",
       "0           0.038966           0.034773            0.032448   \n",
       "\n",
       "   ENSG00000135842.15  ENSG00000270182.1  ENSG00000264918.1  \\\n",
       "0            0.025288           0.019858           0.015346   \n",
       "\n",
       "   ENSG00000171467.14  ...  ENSG00000133985.2  ENSG00000134072.9  \\\n",
       "0            0.011879  ...                0.0                0.0   \n",
       "\n",
       "   ENSG00000134242.14  ENSG00000134470.18  ENSG00000134531.8  \\\n",
       "0                 0.0                 0.0                0.0   \n",
       "\n",
       "   ENSG00000134569.8  ENSG00000134590.12  ENSG00000134716.8  \\\n",
       "0                0.0                 0.0                0.0   \n",
       "\n",
       "   ENSG00000135069.12  ENSG00000158560.13  \n",
       "0                 0.0                 0.0  \n",
       "\n",
       "[1 rows x 1017 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean importance for all the genes for Extra Trees\n",
    "# And then store the results in a new frame.\n",
    "decisionTreeGiniValuesFrameMean = pd.DataFrame(columns = decisionTreeGiniValuesFrame.columns)\n",
    "decisionTreeGiniValuesFrameMean.loc[0] = decisionTreeGiniValuesFrame.mean()\n",
    "# Sort the results based on importance values\n",
    "decisionTreeGiniValuesFrameMean = decisionTreeGiniValuesFrameMean.sort_values(decisionTreeGiniValuesFrameMean.last_valid_index(), axis=1, ascending = False)\n",
    "\n",
    "outputFileName = 'data\\\\{}\\\\{}_decisiontree_feature_importance_average.csv'.format(dataSize, dataSize)\n",
    "decisionTreeGiniValuesFrameMean.transpose().to_csv(outputFileName)\n",
    "decisionTreeGiniValuesFrameMean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Get all the genes that are relevant for the decision tree classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure out the genes that are common between the decision tree and the extra tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the common columns\n",
    "decisionTreeColumns = [col for col in decisionTreeGiniValuesFrameMean.columns if decisionTreeGiniValuesFrameMean[col].iloc[0] > 0]\n",
    "extraTreeColumns = [col for col in extraTreeGiniValuesFrameMean.columns if extraTreeGiniValuesFrameMean[col].iloc[0] > 0]\n",
    "decisionTreeColumns\n",
    "extraTreeColumns\n",
    "\n",
    "# Find the common columns\n",
    "commonColumns = set(decisionTreeColumns).intersection(extraTreeColumns)\n",
    "\n",
    "\n",
    "# Filter the importance values for these columns only\n",
    "commonTreeImportanceValues = decisionTreeGiniValuesFrameMean[list(commonColumns)]\n",
    "commonExtraTreeImportanceValues = extraTreeGiniValuesFrameMean[list(commonColumns)]\n",
    "\n",
    "commonTreeImportanceValues.T.to_csv(\"data\\\\{}\\\\{}_decision_tree_common_importance.csv\".format(dataSize,dataSize))\n",
    "commonExtraTreeImportanceValues.T.to_csv(\"data\\\\{}\\\\{}_extra_tree_common_importance.csv\".format(dataSize,dataSize))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
